# F1.5 - Infrastructure & D√©ploiement

**Score Priorit√© :** 80/100  
**Statut :** PRIORIT√â MOYENNE  
**Epic :** EPIC 1 - FONDATIONS  
**Effort estim√© :** 18 jours  

## Description

Infrastructure robuste et d√©ploiement automatis√© avec containerisation Docker, orchestration PM2, monitoring avanc√©, CI/CD complet et strat√©gies de backup/recovery pour assurer une disponibilit√© et performance optimales du syst√®me Ba≈°-Malin.

## User Stories

### US1.5.1 - D√©ploiement Automatis√©
**En tant qu'** administrateur syst√®me  
**Je veux** un d√©ploiement automatis√© et fiable  
**Afin d'** assurer des mises √† jour sans interruption de service  

**Crit√®res d'acceptation :**
- Pipeline CI/CD avec tests automatis√©s
- D√©ploiement blue-green sans downtime
- Rollback automatique en cas d'√©chec
- Validation post-d√©ploiement automatique
- Notifications d'√©tat de d√©ploiement

### US1.5.2 - Monitoring & Observabilit√©
**En tant qu'** expert jardinier  
**Je veux** que le syst√®me soit toujours disponible et performant  
**Afin de** ne jamais perdre mes donn√©es de jardinage  

**Crit√®res d'acceptation :**
- Monitoring temps r√©el (CPU, RAM, disque, r√©seau)
- Alertes proactives avant les pannes
- Logs centralis√©s avec recherche avanc√©e
- M√©triques business (utilisateurs actifs, donn√©es collect√©es)
- Dashboard de sant√© syst√®me accessible

### US1.5.3 - Sauvegarde & R√©cup√©ration
**En tant qu'** utilisateur expert  
**Je veux** que mes donn√©es soient prot√©g√©es et r√©cup√©rables  
**Afin de** ne jamais perdre l'historique de mon jardin  

**Crit√®res d'acceptation :**
- Sauvegarde automatique quotidienne
- R√©plication multi-zone pour haute disponibilit√©
- Tests de r√©cup√©ration automatis√©s
- RTO < 4h, RPO < 1h
- Export/import des donn√©es utilisateur

## Architecture Technique

### Infrastructure as Code

```yaml
# docker-compose.yml
version: '3.8'

services:
  # Application Next.js
  app:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: basmalin-app
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    depends_on:
      - postgres
      - redis
    networks:
      - basmalin-network
    volumes:
      - uploads:/app/uploads
      - logs:/app/logs
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Base de donn√©es PostgreSQL
  postgres:
    image: postgres:16-alpine
    container_name: basmalin-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
      - ./scripts/postgres-init.sh:/docker-entrypoint-initdb.d/init.sh
    ports:
      - "5432:5432"
    networks:
      - basmalin-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Cache Redis
  redis:
    image: redis:7-alpine
    container_name: basmalin-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf
    ports:
      - "6379:6379"
    networks:
      - basmalin-network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # Reverse Proxy Nginx
  nginx:
    image: nginx:alpine
    container_name: basmalin-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
      - uploads:/usr/share/nginx/html/uploads:ro
    depends_on:
      - app
    networks:
      - basmalin-network
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Monitoring - Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: basmalin-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
    networks:
      - basmalin-network

  # Monitoring - Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: basmalin-grafana
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana:/etc/grafana/provisioning
    networks:
      - basmalin-network

  # Logs - Loki
  loki:
    image: grafana/loki:latest
    container_name: basmalin-loki
    restart: unless-stopped
    ports:
      - "3100:3100"
    volumes:
      - ./config/loki.yml:/etc/loki/local-config.yaml
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - basmalin-network

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
  loki_data:
  uploads:
  logs:

networks:
  basmalin-network:
    driver: bridge
```

### Dockerfile Multi-Stage

```dockerfile
# Dockerfile
FROM node:20-alpine AS base

# D√©pendances syst√®me
RUN apk add --no-cache libc6-compat
WORKDIR /app

# Dependencies
FROM base AS deps
COPY package.json package-lock.json* ./
RUN npm ci --only=production

# Builder
FROM base AS builder
COPY package.json package-lock.json* ./
RUN npm ci
COPY . .

# Variables d'environnement build
ENV NEXT_TELEMETRY_DISABLED 1
ENV NODE_ENV production

# Build de l'application
RUN npm run build

# Runner
FROM base AS runner
WORKDIR /app

ENV NODE_ENV production
ENV NEXT_TELEMETRY_DISABLED 1

# Utilisateur non-root pour s√©curit√©
RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

# Copie des fichiers n√©cessaires
COPY --from=builder /app/public ./public
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static

# Cr√©ation des dossiers de donn√©es
RUN mkdir -p /app/uploads /app/logs
RUN chown nextjs:nodejs /app/uploads /app/logs

USER nextjs

EXPOSE 3000

ENV PORT 3000
ENV HOSTNAME "0.0.0.0"

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js

CMD ["node", "server.js"]
```

### Configuration PM2

```javascript
// ecosystem.config.js
module.exports = {
  apps: [
    {
      name: 'basmalin-app',
      script: 'server.js',
      instances: 'max',
      exec_mode: 'cluster',
      env: {
        NODE_ENV: 'production',
        PORT: 3000
      },
      env_production: {
        NODE_ENV: 'production',
        PORT: 3000
      },
      // Monitoring
      monitoring: true,
      pmx: true,
      
      // Ressources
      max_memory_restart: '1G',
      node_args: '--max-old-space-size=1024',
      
      // Logs
      log_file: './logs/combined.log',
      out_file: './logs/out.log',
      error_file: './logs/error.log',
      log_date_format: 'YYYY-MM-DD HH:mm:ss Z',
      
      // Auto-restart configuration
      watch: false,
      ignore_watch: ['node_modules', 'logs', 'uploads'],
      
      // Graceful reload
      kill_timeout: 5000,
      listen_timeout: 10000,
      
      // Health check
      health_check_grace_period: 10000,
      
      // Cron restart pour √©viter les memory leaks
      cron_restart: '0 2 * * *', // 2h du matin chaque jour
      
      // Variables d'environnement
      env_file: '.env.production'
    }
  ],
  
  deploy: {
    production: {
      user: 'deploy',
      host: ['basmalin-prod.example.com'],
      ref: 'origin/main',
      repo: 'git@github.com:username/basmalin.git',
      path: '/var/www/basmalin',
      'pre-deploy-local': '',
      'post-deploy': 'npm install && npm run build && pm2 reload ecosystem.config.js --env production',
      'pre-setup': ''
    }
  }
};
```

### CI/CD Pipeline

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  NODE_VERSION: '20'
  POSTGRES_VERSION: '16'

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: basmalin_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
          
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Run linting
      run: npm run lint

    - name: Run type checking
      run: npm run type-check

    - name: Setup test database
      run: |
        npm run prisma:push
        npm run db:seed:test
      env:
        DATABASE_URL: postgres://postgres:postgres@localhost:5432/basmalin_test

    - name: Run unit tests
      run: npm run test:unit
      env:
        DATABASE_URL: postgres://postgres:postgres@localhost:5432/basmalin_test
        REDIS_URL: redis://localhost:6379

    - name: Run integration tests
      run: npm run test:integration
      env:
        DATABASE_URL: postgres://postgres:postgres@localhost:5432/basmalin_test
        REDIS_URL: redis://localhost:6379

    - name: Run E2E tests
      run: npm run test:e2e
      env:
        DATABASE_URL: postgres://postgres:postgres@localhost:5432/basmalin_test

    - name: Build application
      run: npm run build
      env:
        NODE_ENV: production

    - name: Generate test coverage
      run: npm run test:coverage

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage/lcov.info
        fail_ci_if_error: true

  security:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Security audit
      run: npm audit --audit-level=high

    - name: Run Snyk security check
      uses: snyk/actions/node@master
      env:
        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

    - name: Container security scan
      run: |
        docker build -t basmalin:test .
        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
          -v $(pwd):/app aquasec/trivy image basmalin:test

  deploy:
    runs-on: ubuntu-latest
    needs: [test, security]
    if: github.ref == 'refs/heads/main'
    
    environment:
      name: production
      url: https://basmalin.example.com
      
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Build and tag Docker image
      run: |
        docker build -t basmalin:${{ github.sha }} .
        docker tag basmalin:${{ github.sha }} basmalin:latest

    - name: Login to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Push Docker image
      run: |
        docker tag basmalin:latest ghcr.io/${{ github.repository }}:latest
        docker tag basmalin:latest ghcr.io/${{ github.repository }}:${{ github.sha }}
        docker push ghcr.io/${{ github.repository }}:latest
        docker push ghcr.io/${{ github.repository }}:${{ github.sha }}

    - name: Deploy to production
      uses: appleboy/ssh-action@v0.1.8
      with:
        host: ${{ secrets.PROD_HOST }}
        username: ${{ secrets.PROD_USER }}
        key: ${{ secrets.PROD_SSH_KEY }}
        script: |
          cd /var/www/basmalin
          
          # Backup avant d√©ploiement
          ./scripts/backup-pre-deploy.sh
          
          # Blue-Green Deployment
          docker-compose -f docker-compose.prod.yml pull
          docker-compose -f docker-compose.prod.yml up -d --no-deps app-blue
          
          # Health check
          sleep 30
          if curl -f http://localhost:3001/api/health; then
            # Switch traffic
            docker-compose -f docker-compose.prod.yml stop app-green
            docker-compose -f docker-compose.prod.yml up -d --no-deps app-green
            docker-compose -f docker-compose.prod.yml stop app-blue
            echo "Deployment successful"
          else
            # Rollback
            docker-compose -f docker-compose.prod.yml stop app-blue
            echo "Deployment failed, rolled back"
            exit 1
          fi
          
          # Cleanup old images
          docker image prune -f

    - name: Run post-deployment tests
      run: |
        npm run test:smoke -- --baseUrl=https://basmalin.example.com

    - name: Notify deployment status
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
      if: always()
```

### Scripts de Monitoring

```bash
#!/bin/bash
# scripts/monitoring/health-check.sh

# Health check complet du syst√®me
echo "=== Ba≈°-Malin System Health Check ==="
echo "Date: $(date)"
echo

# Check services Docker
echo "üì¶ Docker Services Status:"
docker-compose ps --format "table {{.Name}}\t{{.Status}}\t{{.Ports}}"
echo

# Check base de donn√©es
echo "üóÑÔ∏è  Database Health:"
docker exec basmalin-postgres pg_isready -U $POSTGRES_USER -d $POSTGRES_DB
if [ $? -eq 0 ]; then
    echo "‚úÖ PostgreSQL is healthy"
    
    # Check taille de la DB
    DB_SIZE=$(docker exec basmalin-postgres psql -U $POSTGRES_USER -d $POSTGRES_DB -t -c "SELECT pg_size_pretty(pg_database_size('$POSTGRES_DB'));")
    echo "üìä Database size: $DB_SIZE"
else
    echo "‚ùå PostgreSQL is unhealthy"
fi
echo

# Check Redis
echo "üî¥ Redis Health:"
if docker exec basmalin-redis redis-cli -a $REDIS_PASSWORD ping | grep -q PONG; then
    echo "‚úÖ Redis is healthy"
    
    # Check utilisation m√©moire Redis
    REDIS_MEMORY=$(docker exec basmalin-redis redis-cli -a $REDIS_PASSWORD info memory | grep used_memory_human)
    echo "üìä Redis memory: $REDIS_MEMORY"
else
    echo "‚ùå Redis is unhealthy"
fi
echo

# Check application
echo "üöÄ Application Health:"
if curl -f http://localhost:3000/api/health > /dev/null 2>&1; then
    echo "‚úÖ Application is healthy"
    
    # Check temps de r√©ponse
    RESPONSE_TIME=$(curl -o /dev/null -s -w "%{time_total}" http://localhost:3000/api/health)
    echo "‚è±Ô∏è  Response time: ${RESPONSE_TIME}s"
else
    echo "‚ùå Application is unhealthy"
fi
echo

# Check espace disque
echo "üíæ Disk Usage:"
df -h | grep -E '^/dev/' | awk '{print $1 "\t" $3 "/" $2 "\t(" $5 " used)"}'
echo

# Check m√©moire
echo "üß† Memory Usage:"
free -h | awk 'NR==2{printf "%.1f/%.1fGB (%.2f%%)\n", $3/1024/1024,$2/1024/1024,$3*100/$2 }'
echo

# Check load average
echo "‚ö° System Load:"
uptime | awk -F'load average:' '{print $2}'
echo

# Check logs r√©cents pour erreurs
echo "üìã Recent Errors (last 10):"
docker logs basmalin-app --since=1h 2>&1 | grep -i error | tail -10
echo

echo "=== Health Check Complete ==="
```

```typescript
// src/lib/monitoring/metrics.ts
import { NextRequest, NextResponse } from 'next/server';
import { prometheus } from 'prom-client';

// M√©triques personnalis√©es
export const httpRequestDuration = new prometheus.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route', 'status_code'],
  buckets: [0.1, 0.5, 1, 2, 5]
});

export const iotSensorReadings = new prometheus.Counter({
  name: 'iot_sensor_readings_total',
  help: 'Total number of IoT sensor readings',
  labelNames: ['sensor_type', 'device_id', 'status']
});

export const aiInsightsGenerated = new prometheus.Counter({
  name: 'ai_insights_generated_total',
  help: 'Total number of AI insights generated',
  labelNames: ['insight_type', 'model_provider', 'success']
});

export const userSessions = new prometheus.Gauge({
  name: 'user_sessions_active',
  help: 'Number of active user sessions'
});

export const databaseConnections = new prometheus.Gauge({
  name: 'database_connections_active',
  help: 'Number of active database connections'
});

// Middleware de monitoring
export function monitoringMiddleware(request: NextRequest) {
  const start = Date.now();
  const route = request.nextUrl.pathname;
  const method = request.method;

  return new Promise((resolve) => {
    // Wrap original response
    const originalJson = NextResponse.json;
    NextResponse.json = function(body: any, init?: ResponseInit) {
      const response = originalJson.call(this, body, init);
      
      // Enregistrer m√©triques
      const duration = (Date.now() - start) / 1000;
      const statusCode = response.status.toString();
      
      httpRequestDuration
        .labels(method, route, statusCode)
        .observe(duration);
      
      return response;
    };
    
    resolve(undefined);
  });
}

// Health check endpoint
export async function healthCheck(): Promise<HealthStatus> {
  const checks = await Promise.allSettled([
    checkDatabase(),
    checkRedis(),
    checkExternalAPIs(),
    checkDiskSpace(),
    checkMemoryUsage()
  ]);

  const results = checks.map((check, index) => ({
    name: ['database', 'redis', 'external_apis', 'disk_space', 'memory'][index],
    status: check.status === 'fulfilled' ? 'healthy' : 'unhealthy',
    details: check.status === 'fulfilled' ? check.value : check.reason
  }));

  const overall = results.every(r => r.status === 'healthy') ? 'healthy' : 'unhealthy';

  return {
    status: overall,
    timestamp: new Date().toISOString(),
    checks: results,
    uptime: process.uptime(),
    version: process.env.npm_package_version || 'unknown'
  };
}
```

## Scripts de Backup

```bash
#!/bin/bash
# scripts/backup/automated-backup.sh

set -e

BACKUP_DIR="/backups/$(date +%Y-%m-%d)"
RETENTION_DAYS=30

echo "üîÑ Starting automated backup - $(date)"

# Cr√©ation du dossier de backup
mkdir -p $BACKUP_DIR

# Backup PostgreSQL
echo "üìä Backing up PostgreSQL..."
docker exec basmalin-postgres pg_dump -U $POSTGRES_USER -d $POSTGRES_DB | gzip > $BACKUP_DIR/postgres-$(date +%H%M%S).sql.gz

# Backup Redis
echo "üî¥ Backing up Redis..."
docker exec basmalin-redis redis-cli -a $REDIS_PASSWORD --rdb /data/dump.rdb
docker cp basmalin-redis:/data/dump.rdb $BACKUP_DIR/redis-$(date +%H%M%S).rdb

# Backup uploads/files
echo "üìÅ Backing up files..."
tar -czf $BACKUP_DIR/uploads-$(date +%H%M%S).tar.gz -C /var/www/basmalin uploads/

# Backup configuration
echo "‚öôÔ∏è  Backing up configuration..."
cp -r /var/www/basmalin/config $BACKUP_DIR/

# Upload to S3 (optionnel)
if [ -n "$AWS_S3_BUCKET" ]; then
    echo "‚òÅÔ∏è  Uploading to S3..."
    aws s3 sync $BACKUP_DIR s3://$AWS_S3_BUCKET/backups/$(date +%Y-%m-%d)/
fi

# Cleanup old backups
echo "üßπ Cleaning up old backups..."
find /backups -type d -mtime +$RETENTION_DAYS -exec rm -rf {} +

echo "‚úÖ Backup completed - $(date)"

# Test restore (weekly)
if [ $(date +%u) -eq 1 ]; then # Lundi
    echo "üß™ Running weekly restore test..."
    ./scripts/backup/test-restore.sh $BACKUP_DIR
fi
```

## Crit√®res d'Acceptation Techniques

### Disponibilit√©
- [ ] Uptime > 99.5% (4h de downtime max/mois)
- [ ] D√©ploiement blue-green sans interruption
- [ ] Auto-healing des services d√©faillants
- [ ] Monitoring proactif avec alertes

### Performance
- [ ] Temps de r√©ponse API < 200ms (P95)
- [ ] Build Docker < 5 minutes
- [ ] D√©ploiement complet < 10 minutes
- [ ] R√©cup√©ration apr√®s panne < 15 minutes

### S√©curit√©
- [ ] Images Docker scann√©es (zero vuln√©rabilit√©s critiques)
- [ ] Secrets g√©r√©s via variables d'environnement
- [ ] Logs centralis√©s sans donn√©es sensibles
- [ ] Backups chiffr√©s

## Couverture Exigences Architecture

- **EXG-001.1** : Next.js 14 en production avec PM2
- **EXG-002.1** : PostgreSQL avec r√©plication
- **EXG-002.2** : Redis clustering pour cache
- **EXG-009.1** : Monitoring complet Prometheus/Grafana
- **EXG-009.2** : Logging centralis√© avec Loki
- **EXG-010.1** : Infrastructure containeris√©e

## Tests d'Acceptation

```typescript
// tests/infrastructure/deployment.test.ts
describe('Infrastructure & Deployment', () => {
  test('health check endpoint r√©pond correctement', async () => {
    const response = await fetch('/api/health');
    const health = await response.json();
    
    expect(response.status).toBe(200);
    expect(health.status).toBe('healthy');
    expect(health.checks).toBeDefined();
  });

  test('m√©triques Prometheus sont expos√©es', async () => {
    const response = await fetch('/api/metrics');
    const metrics = await response.text();
    
    expect(response.status).toBe(200);
    expect(metrics).toContain('http_request_duration_seconds');
    expect(metrics).toContain('iot_sensor_readings_total');
  });

  test('backup automatique fonctionne', async () => {
    const backupResult = await execScript('./scripts/backup/automated-backup.sh');
    
    expect(backupResult.exitCode).toBe(0);
    expect(backupResult.output).toContain('Backup completed');
  });
});

// tests/load/performance.test.ts
describe('Performance Tests', () => {
  test('API supporte 100 req/s concurrent', async () => {
    const results = await loadTest({
      url: '/api/gardens',
      concurrent: 100,
      duration: '30s'
    });
    
    expect(results.averageResponseTime).toBeLessThan(200);
    expect(results.errorRate).toBeLessThan(0.01);
  });
});
```

Cette sp√©cification couvre une infrastructure compl√®te et robuste assurant la fiabilit√©, performance et s√©curit√© du syst√®me Ba≈°-Malin en production.