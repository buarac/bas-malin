# F5.4 - Computer Vision Avancée

**Score Priorité :** 45/100  
**Statut :** PRIORITÉ FAIBLE  
**Epic :** EPIC 5 - IA AVANCÉE & PRÉDICTIONS  
**Effort estimé :** 25 jours  

## Description

Système de computer vision avancé pour reconnaissance automatique de maladies, identification des stades de croissance, suivi évolution temporelle des cultures et génération de time-lapse avec analyse intelligente des transformations.

## User Stories

### US5.4.1 - Diagnostic Automatique Maladies
**En tant qu'** jardinier  
**Je veux** diagnostiquer automatiquement les maladies de mes plantes avec une photo  
**Afin de** détecter précocement les problèmes et agir rapidement  

**Critères d'acceptation :**
- Reconnaissance 20+ maladies communes (>80% précision)
- Diagnostic avec niveau de confiance et zones affectées
- Recommandations traitement spécifiques à la maladie
- Détection précoce avant symptômes visibles humains
- Base de données symptômes évolutive

### US5.4.2 - Suivi Croissance Automatique
**En tant qu'** utilisateur  
**Je veux** suivre automatiquement l'évolution de mes cultures  
**Afin de** comprendre leur développement et optimiser les soins  

**Critères d'acceptation :**
- Reconnaissance stades croissance par espèce
- Mesures automatiques (taille, volume, maturité)
- Comparaison avec standards de croissance
- Alertes croissance anormale ou retard
- Historique visuel avec métriques

### US5.4.3 - Time-lapse Intelligent
**En tant qu'** passionné  
**Je veux** créer des time-lapse intelligents de mes cultures  
**Afin de** visualiser et partager l'évolution de mon jardin  

**Critères d'acceptation :**
- Alignement automatique des photos séquentielles
- Génération time-lapse avec points d'intérêt
- Analyse narrative de l'évolution
- Détection événements marquants (floraison, fructification)
- Export vidéo haute qualité avec métadonnées

## Architecture Technique

### Service Computer Vision

```typescript
// src/services/vision/computer-vision.service.ts
export interface PlantAnalysis {
  species?: {
    name: string;
    confidence: number;
    family: string;
    characteristics: string[];
  };
  health: {
    overall: 'excellent' | 'good' | 'fair' | 'poor' | 'critical';
    score: number; // 0-100
    issues: HealthIssue[];
  };
  growth: {
    stage: GrowthStage;
    progress: number; // % vers next stage
    metrics: GrowthMetrics;
  };
  recommendations: VisionRecommendation[];
}

export interface HealthIssue {
  type: 'disease' | 'pest' | 'deficiency' | 'environmental';
  name: string;
  severity: 'low' | 'medium' | 'high' | 'critical';
  confidence: number;
  affectedAreas: BoundingBox[];
  symptoms: string[];
  causes: string[];
  treatments: Treatment[];
}

export interface GrowthStage {
  name: string;
  description: string;
  typicalDuration: string;
  nextStage?: string;
  characteristics: string[];
}

export interface GrowthMetrics {
  estimatedHeight: number;
  leafCount?: number;
  flowerCount?: number;
  fruitCount?: number;
  biomassEstimate: number;
  maturityPercentage: number;
}

export class ComputerVisionService {
  private openaiClient: OpenAI;
  private plantNetClient: PlantNetAPI;
  private diseaseModels: Map<string, MLModel>;
  private growthModels: Map<string, MLModel>;

  constructor(
    private prisma: PrismaClient,
    private storageService: StorageService,
    private mlService: MLService
  ) {
    this.openaiClient = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
    this.plantNetClient = new PlantNetAPI();
    this.diseaseModels = new Map();
    this.growthModels = new Map();
    this.initializeModels();
  }

  async analyzeImage(
    imageBuffer: Buffer,
    metadata: ImageMetadata,
    analysisTypes: ('species' | 'health' | 'growth')[] = ['species', 'health', 'growth']
  ): Promise<PlantAnalysis> {
    // Upload et préparation de l'image
    const imageUrl = await this.uploadAnalysisImage(imageBuffer, metadata);
    const processedImage = await this.preprocessImage(imageBuffer);

    const analysis: Partial<PlantAnalysis> = {};

    // Analyse d'espèce si demandée
    if (analysisTypes.includes('species')) {
      analysis.species = await this.identifySpecies(processedImage, imageUrl);
    }

    // Analyse de santé si demandée
    if (analysisTypes.includes('health')) {
      analysis.health = await this.analyzeHealth(
        processedImage, 
        imageUrl, 
        analysis.species?.name
      );
    }

    // Analyse de croissance si demandée
    if (analysisTypes.includes('growth')) {
      analysis.growth = await this.analyzeGrowth(
        processedImage, 
        imageUrl, 
        analysis.species?.name
      );
    }

    // Génération des recommandations globales
    analysis.recommendations = await this.generateRecommendations(
      analysis as PlantAnalysis,
      metadata
    );

    // Sauvegarde de l'analyse
    await this.saveAnalysis(imageUrl, analysis, metadata);

    return analysis as PlantAnalysis;
  }

  private async identifySpecies(
    processedImage: ProcessedImage,
    imageUrl: string
  ): Promise<PlantAnalysis['species']> {
    // Utilisation combinée de GPT-4 Vision et PlantNet
    const [visionResult, plantNetResult] = await Promise.all([
      this.identifyWithVision(imageUrl),
      this.identifyWithPlantNet(processedImage.buffer)
    ]);

    // Fusion des résultats pour améliorer la précision
    return this.fusionSpeciesResults(visionResult, plantNetResult);
  }

  private async identifyWithVision(imageUrl: string): Promise<any> {
    const completion = await this.openaiClient.chat.completions.create({
      model: 'gpt-4-vision-preview',
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: `Identifie cette plante avec le maximum de précision. Fournis:
1. Nom scientifique et nom commun
2. Famille botanique
3. Caractéristiques distinctives visibles
4. Niveau de confiance de l'identification
5. Plante potagère ou ornementale?

Format ta réponse en JSON avec les champs: scientificName, commonName, family, characteristics, confidence, type`
            },
            {
              type: 'image_url',
              image_url: { url: imageUrl }
            }
          ]
        }
      ],
      max_tokens: 500
    });

    return JSON.parse(completion.choices[0].message.content || '{}');
  }

  private async identifyWithPlantNet(imageBuffer: Buffer): Promise<any> {
    try {
      const result = await this.plantNetClient.identify({
        images: [imageBuffer],
        modifiers: ['crops', 'useful'],
        includeRelatedImages: false
      });

      return result.results[0]; // Meilleur match
    } catch (error) {
      console.warn('PlantNet identification failed:', error);
      return null;
    }
  }

  private async analyzeHealth(
    processedImage: ProcessedImage,
    imageUrl: string,
    speciesName?: string
  ): Promise<PlantAnalysis['health']> {
    // Analyse combinée vision + modèles spécialisés
    const [visionAnalysis, mlAnalysis] = await Promise.all([
      this.analyzeHealthWithVision(imageUrl, speciesName),
      this.analyzeHealthWithML(processedImage, speciesName)
    ]);

    return this.fusionHealthResults(visionAnalysis, mlAnalysis);
  }

  private async analyzeHealthWithVision(
    imageUrl: string,
    speciesName?: string
  ): Promise<any> {
    const speciesContext = speciesName 
      ? `Cette plante est identifiée comme: ${speciesName}. ` 
      : '';

    const completion = await this.openaiClient.chat.completions.create({
      model: 'gpt-4-vision-preview',
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: `${speciesContext}Analyse la santé de cette plante en détail:

1. État général de santé (score 0-100)
2. Problèmes visibles (maladies, parasites, carences)
3. Zones affectées avec pourcentages
4. Symptômes observés
5. Causes probables
6. Urgence du traitement (low/medium/high/critical)
7. Traitements recommandés

Format JSON avec: overallScore, issues, affectedAreas, symptoms, treatments`
            },
            {
              type: 'image_url',
              image_url: { url: imageUrl }
            }
          ]
        }
      ],
      max_tokens: 1000
    });

    return JSON.parse(completion.choices[0].message.content || '{}');
  }

  private async analyzeHealthWithML(
    processedImage: ProcessedImage,
    speciesName?: string
  ): Promise<any> {
    // Sélection du modèle selon l'espèce
    const modelKey = speciesName ? `disease_${speciesName.toLowerCase()}` : 'disease_general';
    const model = this.diseaseModels.get(modelKey) || this.diseaseModels.get('disease_general');

    if (!model) {
      return { confidence: 0, diseases: [] };
    }

    // Features extraction pour le modèle ML
    const features = await this.extractHealthFeatures(processedImage);

    // Prédiction des maladies
    const predictions = await model.predict(features);

    return this.parseMLHealthResults(predictions);
  }

  private async analyzeGrowth(
    processedImage: ProcessedImage,
    imageUrl: string,
    speciesName?: string
  ): Promise<PlantAnalysis['growth']> {
    const [visionGrowth, mlGrowth] = await Promise.all([
      this.analyzeGrowthWithVision(imageUrl, speciesName),
      this.analyzeGrowthWithML(processedImage, speciesName)
    ]);

    return this.fusionGrowthResults(visionGrowth, mlGrowth);
  }

  private async analyzeGrowthWithVision(
    imageUrl: string,
    speciesName?: string
  ): Promise<any> {
    const speciesContext = speciesName 
      ? `Cette plante est: ${speciesName}. ` 
      : '';

    const completion = await this.openaiClient.chat.completions.create({
      model: 'gpt-4-vision-preview',
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: `${speciesContext}Analyse le stade de croissance de cette plante:

1. Stade actuel (germination, croissance, floraison, fructification, maturité)
2. Progression vers le stade suivant (0-100%)
3. Métriques visuelles (hauteur approximative, nombre de feuilles/fleurs/fruits)
4. Comparaison avec croissance normale pour cette espèce
5. Signes de maturation
6. Estimation biomasse

Format JSON: stage, progressPercentage, metrics, maturitySigns`
            },
            {
              type: 'image_url',
              image_url: { url: imageUrl }
            }
          ]
        }
      ],
      max_tokens: 600
    });

    return JSON.parse(completion.choices[0].message.content || '{}');
  }

  // Système de Time-lapse intelligent
  async createTimeLapse(
    imageSequence: TimelapseImage[],
    config: TimelapseConfig
  ): Promise<TimelapseResult> {
    // Tri et validation de la séquence
    const sortedImages = this.sortAndValidateSequence(imageSequence);
    
    // Alignement automatique des images
    const alignedImages = await this.alignImages(sortedImages);
    
    // Analyse de l'évolution
    const evolutionAnalysis = await this.analyzeEvolution(alignedImages);
    
    // Détection des événements marquants
    const keyEvents = await this.detectKeyEvents(evolutionAnalysis);
    
    // Génération du time-lapse
    const timelapseVideo = await this.generateTimelapse(alignedImages, {
      ...config,
      keyEvents,
      evolutionData: evolutionAnalysis
    });

    // Génération narrative
    const narrative = await this.generateEvolutionNarrative(evolutionAnalysis, keyEvents);

    return {
      videoUrl: timelapseVideo.url,
      duration: timelapseVideo.duration,
      frameCount: alignedImages.length,
      evolutionAnalysis,
      keyEvents,
      narrative,
      metadata: {
        startDate: sortedImages[0].timestamp,
        endDate: sortedImages[sortedImages.length - 1].timestamp,
        totalDays: this.calculateDaysBetween(sortedImages[0].timestamp, sortedImages[sortedImages.length - 1].timestamp)
      }
    };
  }

  private async alignImages(images: TimelapseImage[]): Promise<AlignedImage[]> {
    // Détection des points clés sur la première image (référence)
    const referenceKeypoints = await this.detectKeypoints(images[0]);
    
    const alignedImages: AlignedImage[] = [{
      ...images[0],
      transform: this.identityTransform(),
      alignmentScore: 1.0
    }];

    // Alignement des images suivantes
    for (let i = 1; i < images.length; i++) {
      const currentKeypoints = await this.detectKeypoints(images[i]);
      const transform = await this.calculateTransform(referenceKeypoints, currentKeypoints);
      const alignedImage = await this.applyTransform(images[i], transform);
      
      alignedImages.push({
        ...images[i],
        transform,
        alignmentScore: this.calculateAlignmentScore(referenceKeypoints, currentKeypoints)
      });
    }

    return alignedImages;
  }

  private async analyzeEvolution(images: AlignedImage[]): Promise<EvolutionAnalysis> {
    const analysisPoints: EvolutionPoint[] = [];
    
    for (const image of images) {
      const analysis = await this.analyzeImage(
        Buffer.from(image.buffer), 
        image.metadata, 
        ['health', 'growth']
      );
      
      analysisPoints.push({
        timestamp: image.timestamp,
        healthScore: analysis.health.score,
        growthMetrics: analysis.growth.metrics,
        stage: analysis.growth.stage.name,
        issues: analysis.health.issues
      });
    }

    return {
      points: analysisPoints,
      trends: this.calculateTrends(analysisPoints),
      milestones: this.identifyMilestones(analysisPoints)
    };
  }

  private async detectKeyEvents(evolution: EvolutionAnalysis): Promise<KeyEvent[]> {
    const events: KeyEvent[] = [];

    for (let i = 1; i < evolution.points.length; i++) {
      const current = evolution.points[i];
      const previous = evolution.points[i - 1];

      // Détection changement de stade
      if (current.stage !== previous.stage) {
        events.push({
          type: 'stage_change',
          timestamp: current.timestamp,
          description: `Passage de ${previous.stage} à ${current.stage}`,
          significance: 'high'
        });
      }

      // Détection croissance rapide
      const growthRate = this.calculateGrowthRate(previous, current);
      if (growthRate > 1.5) { // 150% du taux normal
        events.push({
          type: 'rapid_growth',
          timestamp: current.timestamp,
          description: `Croissance accélérée détectée`,
          significance: 'medium'
        });
      }

      // Détection problèmes de santé
      const healthDrop = previous.healthScore - current.healthScore;
      if (healthDrop > 20) {
        events.push({
          type: 'health_issue',
          timestamp: current.timestamp,
          description: `Détérioration de santé: -${healthDrop} points`,
          significance: 'high'
        });
      }
    }

    return events.sort((a, b) => b.significance.localeCompare(a.significance));
  }

  private async generateEvolutionNarrative(
    evolution: EvolutionAnalysis,
    keyEvents: KeyEvent[]
  ): Promise<string> {
    const prompt = `Génère un récit captivant de l'évolution de cette plante basé sur les données suivantes:

Données d'évolution:
${JSON.stringify(evolution, null, 2)}

Événements clés:
${JSON.stringify(keyEvents, null, 2)}

Écris un récit de 200-300 mots qui:
1. Raconte l'histoire de croissance de cette plante
2. Met en valeur les moments marquants
3. Explique les défis surmontés
4. Utilise un ton passionnant et éducatif
5. Inclut des détails techniques accessibles`;

    const completion = await this.openaiClient.chat.completions.create({
      model: 'gpt-4-turbo-preview',
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 500
    });

    return completion.choices[0].message.content || '';
  }

  // Training et amélioration des modèles
  async trainDiseaseModel(
    speciesName: string,
    trainingData: DiseaseTrainingData[]
  ): Promise<void> {
    const modelId = `disease_${speciesName.toLowerCase()}`;
    
    // Préparation des données d'entraînement
    const processedData = await this.preprocessTrainingData(trainingData);
    
    // Configuration du modèle
    const modelConfig = {
      architecture: 'CNN',
      layers: [
        { type: 'conv2d', filters: 32, kernelSize: 3 },
        { type: 'maxpool2d', poolSize: 2 },
        { type: 'conv2d', filters: 64, kernelSize: 3 },
        { type: 'maxpool2d', poolSize: 2 },
        { type: 'flatten' },
        { type: 'dense', units: 128, activation: 'relu' },
        { type: 'dropout', rate: 0.3 },
        { type: 'dense', units: trainingData[0].diseases.length, activation: 'softmax' }
      ],
      optimizer: 'adam',
      loss: 'categorical_crossentropy',
      metrics: ['accuracy']
    };

    // Entraînement
    const model = await this.mlService.trainModel(modelConfig, processedData);
    
    // Validation
    const validationResult = await this.validateModel(model, processedData.validationSet);
    
    if (validationResult.accuracy >= 0.8) {
      // Sauvegarde du modèle
      await this.saveModel(model, modelId);
      this.diseaseModels.set(modelId, model);
      
      console.log(`Disease model for ${speciesName} trained successfully. Accuracy: ${validationResult.accuracy}`);
    } else {
      throw new Error(`Model accuracy too low: ${validationResult.accuracy}`);
    }
  }
}
```

### Interface Computer Vision

```typescript
// src/app/vision/page.tsx
export default function ComputerVisionPage() {
  const [analysisResult, setAnalysisResult] = useState<PlantAnalysis | null>(null);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [activeTab, setActiveTab] = useState<'analysis' | 'timelapse' | 'history'>('analysis');

  return (
    <div className="container mx-auto py-6">
      <div className="max-w-6xl mx-auto">
        <div className="flex justify-between items-center mb-6">
          <div>
            <h1 className="text-2xl font-bold">🔍 Vision Intelligente</h1>
            <p className="text-gray-600">Analyse automatique de vos plantes</p>
          </div>
        </div>

        <div className="grid grid-cols-12 gap-6">
          {/* Upload et analyse */}
          <div className="col-span-5">
            <Card className="p-6">
              <h3 className="text-lg font-semibold mb-4">Analyser une Image</h3>
              
              <PhotoUpload
                onUpload={handlePhotoAnalysis}
                disabled={isAnalyzing}
              />

              {isAnalyzing && (
                <div className="mt-4 p-4 bg-blue-50 rounded-lg">
                  <div className="flex items-center space-x-2">
                    <Loader2Icon className="w-4 h-4 animate-spin" />
                    <span className="text-sm">Analyse en cours...</span>
                  </div>
                  <Progress value={analysisProgress} className="mt-2" />
                </div>
              )}
            </Card>

            {analysisResult && (
              <Card className="p-6 mt-4">
                <h3 className="text-lg font-semibold mb-4">Recommandations</h3>
                <RecommendationsList recommendations={analysisResult.recommendations} />
              </Card>
            )}
          </div>

          {/* Résultats */}
          <div className="col-span-7">
            {analysisResult ? (
              <div className="space-y-4">
                <SpeciesIdentificationCard species={analysisResult.species} />
                <HealthAnalysisCard health={analysisResult.health} />
                <GrowthAnalysisCard growth={analysisResult.growth} />
              </div>
            ) : (
              <Card className="p-8 text-center">
                <CameraIcon className="w-16 h-16 mx-auto text-gray-400 mb-4" />
                <h3 className="text-lg font-medium mb-2">Prêt à analyser</h3>
                <p className="text-gray-600">
                  Uploadez une photo pour commencer l'analyse automatique
                </p>
              </Card>
            )}
          </div>
        </div>
      </div>
    </div>
  );
}

const SpeciesIdentificationCard = ({ species }: { species?: PlantAnalysis['species'] }) => {
  if (!species) return null;

  return (
    <Card className="p-4">
      <div className="flex items-start space-x-3">
        <div className="w-10 h-10 bg-green-100 rounded-lg flex items-center justify-center">
          <LeafIcon className="w-5 h-5 text-green-600" />
        </div>
        
        <div className="flex-1">
          <div className="flex items-center justify-between mb-2">
            <h3 className="font-semibold">Identification</h3>
            <Badge variant="outline">
              {Math.round(species.confidence * 100)}% confiance
            </Badge>
          </div>
          
          <p className="font-medium">{species.name}</p>
          <p className="text-sm text-gray-600">{species.family}</p>
          
          <div className="mt-3 space-y-1">
            <p className="text-xs font-medium text-gray-700">Caractéristiques:</p>
            {species.characteristics.slice(0, 3).map((char, index) => (
              <p key={index} className="text-xs text-gray-600">• {char}</p>
            ))}
          </div>
        </div>
      </div>
    </Card>
  );
};

const HealthAnalysisCard = ({ health }: { health: PlantAnalysis['health'] }) => {
  const healthColor = {
    excellent: 'text-green-600',
    good: 'text-green-500',
    fair: 'text-yellow-500',
    poor: 'text-orange-500',
    critical: 'text-red-500'
  }[health.overall];

  return (
    <Card className="p-4">
      <div className="flex items-start space-x-3">
        <div className="w-10 h-10 bg-blue-100 rounded-lg flex items-center justify-center">
          <HeartIcon className="w-5 h-5 text-blue-600" />
        </div>
        
        <div className="flex-1">
          <div className="flex items-center justify-between mb-2">
            <h3 className="font-semibold">État de Santé</h3>
            <div className="text-right">
              <div className={`font-bold ${healthColor} capitalize`}>
                {health.overall}
              </div>
              <div className="text-sm text-gray-600">
                {health.score}/100
              </div>
            </div>
          </div>

          <Progress value={health.score} className="mb-3" />

          {health.issues.length > 0 && (
            <div className="space-y-2">
              <p className="text-xs font-medium text-gray-700">Problèmes détectés:</p>
              {health.issues.map((issue, index) => (
                <HealthIssueItem key={index} issue={issue} />
              ))}
            </div>
          )}
        </div>
      </div>
    </Card>
  );
};

const HealthIssueItem = ({ issue }: { issue: HealthIssue }) => {
  const severityColor = {
    low: 'text-yellow-600 bg-yellow-50',
    medium: 'text-orange-600 bg-orange-50',
    high: 'text-red-600 bg-red-50',
    critical: 'text-red-700 bg-red-100'
  }[issue.severity];

  return (
    <div className={`p-2 rounded text-xs ${severityColor}`}>
      <div className="flex justify-between items-center">
        <span className="font-medium">{issue.name}</span>
        <span className="text-xs">
          {Math.round(issue.confidence * 100)}% confiance
        </span>
      </div>
      <p className="mt-1 text-xs opacity-80">
        {issue.symptoms.join(', ')}
      </p>
    </div>
  );
};

const TimelapseCreator = () => {
  const [imageSequence, setImageSequence] = useState<File[]>([]);
  const [isGenerating, setIsGenerating] = useState(false);
  const [timelapseResult, setTimelapseResult] = useState<TimelapseResult | null>(null);

  return (
    <div className="space-y-6">
      <Card className="p-6">
        <h3 className="text-lg font-semibold mb-4">Créer un Time-lapse</h3>
        
        <div className="space-y-4">
          <div>
            <label className="block text-sm font-medium mb-2">
              Séquence d'images ({imageSequence.length} photos)
            </label>
            <MultiImageUpload
              images={imageSequence}
              onChange={setImageSequence}
              maxImages={100}
            />
          </div>

          <div className="grid grid-cols-2 gap-4">
            <div>
              <label className="block text-sm font-medium mb-1">Durée finale</label>
              <Select>
                <SelectTrigger>
                  <SelectValue placeholder="Sélectionner" />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="5s">5 secondes</SelectItem>
                  <SelectItem value="10s">10 secondes</SelectItem>
                  <SelectItem value="15s">15 secondes</SelectItem>
                  <SelectItem value="30s">30 secondes</SelectItem>
                </SelectContent>
              </Select>
            </div>
            
            <div>
              <label className="block text-sm font-medium mb-1">Qualité</label>
              <Select>
                <SelectTrigger>
                  <SelectValue placeholder="HD" />
                </SelectTrigger>
                <SelectContent>
                  <SelectItem value="720p">HD (720p)</SelectItem>
                  <SelectItem value="1080p">Full HD (1080p)</SelectItem>
                  <SelectItem value="4k">4K</SelectItem>
                </SelectContent>
              </Select>
            </div>
          </div>

          <Button 
            onClick={handleGenerateTimelapse}
            disabled={imageSequence.length < 5 || isGenerating}
            className="w-full"
          >
            {isGenerating ? (
              <>
                <Loader2Icon className="w-4 h-4 mr-2 animate-spin" />
                Génération en cours...
              </>
            ) : (
              <>
                <VideoIcon className="w-4 h-4 mr-2" />
                Générer le Time-lapse
              </>
            )}
          </Button>
        </div>
      </Card>

      {timelapseResult && (
        <TimelapseResultCard result={timelapseResult} />
      )}
    </div>
  );
};
```

## Critères d'Acceptation Techniques

### Reconnaissance Maladies
- [ ] 20+ maladies communes identifiées >80% précision
- [ ] Localisation zones affectées avec bounding boxes
- [ ] Diagnostic avec niveau de confiance calibré
- [ ] Recommandations traitement contextualisées
- [ ] Base de données symptômes extensible

### Suivi Croissance
- [ ] Reconnaissance stades par espèce végétale
- [ ] Mesures automatiques (hauteur, volume, comptage)
- [ ] Comparaison avec standards croissance
- [ ] Détection anomalies et retards
- [ ] Historique évolution avec métriques

### Time-lapse Intelligent
- [ ] Alignement automatique séquences photos
- [ ] Génération vidéo haute qualité (jusqu'à 4K)
- [ ] Détection événements marquants automatique
- [ ] Analyse narrative de l'évolution
- [ ] Export avec métadonnées enrichies

## Couverture Exigences Architecture

- **EXG-005.1** : Computer Vision avancée avec ML
- **EXG-005.2** : Modèles d'IA spécialisés entraînables
- **EXG-002.1** : Stockage images et analyses
- **EXG-003.1** : Interface responsive vision
- **EXG-009.1** : Métriques précision et coûts

## Tests d'Acceptation

```typescript
// tests/integration/computer-vision.test.ts
describe('Computer Vision Service', () => {
  test('identification espèce avec confiance', async () => {
    const imageBuffer = await fs.readFile('test-tomato-plant.jpg');
    const analysis = await visionService.analyzeImage(imageBuffer, testMetadata, ['species']);
    
    expect(analysis.species?.name).toContain('Solanum');
    expect(analysis.species?.confidence).toBeGreaterThan(0.8);
  });

  test('détection maladie avec localisation', async () => {
    const diseaseImageBuffer = await fs.readFile('test-plant-disease.jpg');
    const analysis = await visionService.analyzeImage(diseaseImageBuffer, testMetadata, ['health']);
    
    expect(analysis.health.issues).toHaveLength(greaterThan(0));
    expect(analysis.health.issues[0].affectedAreas).toBeDefined();
    expect(analysis.health.issues[0].confidence).toBeGreaterThan(0.7);
  });

  test('génération time-lapse avec événements', async () => {
    const imageSequence = await loadTestImageSequence();
    const timelapse = await visionService.createTimeLapse(imageSequence, {
      duration: 10,
      fps: 30,
      quality: '1080p'
    });
    
    expect(timelapse.videoUrl).toBeDefined();
    expect(timelapse.keyEvents.length).toBeGreaterThan(0);
    expect(timelapse.narrative).toContain('évolution');
  });
});
```

Cette spécification couvre un système complet de computer vision pour diagnostic automatique, suivi de croissance et création de time-lapse intelligents.