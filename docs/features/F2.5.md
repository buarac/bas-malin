# **F2.5 - Gestion des R√©coltes + Reconnaissance IA**

## **üìã Informations g√©n√©rales**
- **Score de priorit√©** : 98/100 ‚≠ê **MUST HAVE PRIORIT√â 1**
- **EPIC** : PILIER PRODUIRE - CORE FEATURES  
- **Complexit√©** : Tr√®s √©lev√©e (Computer Vision + API IA)
- **Devices** : üì±üíªüì∫

## **üéØ Description**
Syst√®me de gestion des r√©coltes avec reconnaissance visuelle IA automatique permettant l'identification de la culture, l'estimation du poids et la d√©tection du type de r√©cipient via photo, avec interface ultra-simplifi√©e pour utilisateurs occasionnels et tra√ßabilit√© compl√®te "de la graine √† l'assiette".

## **üë• User Stories**

### **Jardinier Expert (Sacha)**
- En tant que jardinier exp√©riment√©, je veux enregistrer mes r√©coltes rapidement avec une photo et obtenir une reconnaissance automatique
- En tant qu'utilisateur, je veux tracer mes r√©coltes depuis le semis jusqu'√† la consommation avec g√©olocalisation pr√©cise
- En tant qu'analyste de donn√©es, je veux des m√©triques compl√®tes sur mes rendements et leur √©volution

### **Utilisateur Occasionnel (√âpouse)**
- En tant qu'√©pouse, je veux une interface ultra-simple : photo ‚Üí reconnaissance automatique ‚Üí validation en 1 clic
- En tant qu'utilisateur occasionnel, je veux que l'IA fasse le maximum de travail pour moi
- En tant qu'utilisateur novice, je veux des interfaces guid√©es sans possibilit√© d'erreur

### **Syst√®me IA**
- En tant qu'IA, je dois reconna√Ætre la culture avec 95% de pr√©cision minimum
- En tant qu'IA, je dois estimer le poids et d√©tecter le type de r√©cipient automatiquement
- En tant qu'syst√®me, je dois m'am√©liorer continuellement via feedback utilisateur

## **ü§ñ Sp√©cifications IA (C≈ìur technique)**

### **Computer Vision Pipeline**
```typescript
// Service de reconnaissance IA avec OpenAI GPT-4 Vision
export class HarvestRecognitionService {
  private openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
  });

  async analyzeHarvest(imageBuffer: Buffer): Promise<HarvestAnalysis> {
    const base64Image = imageBuffer.toString('base64');
    
    const response = await this.openai.chat.completions.create({
      model: "gpt-4-vision-preview",
      messages: [{
        role: "user",
        content: [{
          type: "text", 
          text: `Analysez cette photo de r√©colte et identifiez :
          1. Culture exacte (vari√©t√© si possible)
          2. Poids estim√© en kg (pr√©cision ¬±10%)
          3. Type r√©cipient (panier, cagette, bol, assiette, etc.)
          4. Nombre d'unit√©s si applicable
          5. Qualit√© visuelle (1-5)
          6. Stade maturit√©
          
          R√©pondez en JSON avec scores de confiance.`
        }, {
          type: "image_url",
          image_url: { url: `data:image/jpeg;base64,${base64Image}` }
        }]
      }],
      max_tokens: 500
    });

    return this.parseAIResponse(response.choices[0].message.content);
  }

  private parseAIResponse(content: string): HarvestAnalysis {
    // Parse r√©ponse JSON de l'IA
    // Validation des scores de confiance
    // Fallback si confiance < seuil
  }
}

interface HarvestAnalysis {
  culture: {
    nom: string;
    variete?: string;
    scoreConfiance: number; // 0-1
  };
  poidsEstime: {
    kg: number;
    scoreConfiance: number;
    margeErreur: number; // ¬±%
  };
  recipient: {
    type: string;
    scoreConfiance: number;
  };
  qualite: {
    noteGenerale: number; // 1-5
    noteApparence: number;
    stageMaturite: string;
  };
  metadonnees: {
    tempsTraitementMs: number;
    versionModele: string;
    coutEstimeEuros: number;
  };
}
```

### **Queue asynchrone BullMQ**
```typescript
// Job de traitement IA asynchrone (EXG-005.2)
export class HarvestAIQueue {
  private queue = new Queue('harvest-recognition', {
    connection: redis,
    defaultJobOptions: {
      removeOnComplete: 100,
      removeOnFail: 50,
      attempts: 3,
      backoff: 'exponential'
    }
  });

  async processHarvest(recolteId: string, imageUrl: string) {
    return this.queue.add('analyze-harvest', {
      recolteId,
      imageUrl,
      priority: 'high', // R√©coltes = priorit√© haute
      timeout: 30000    // 30s max (EXG-005.2 < 5s)
    });
  }
}

// Worker de traitement
export const harvestWorker = new Worker('harvest-recognition', async (job) => {
  const { recolteId, imageUrl } = job.data;
  
  try {
    // 1. Download image
    const imageBuffer = await downloadImage(imageUrl);
    
    // 2. AI Analysis
    const analysis = await harvestService.analyzeHarvest(imageBuffer);
    
    // 3. Update database
    await prisma.recolte.update({
      where: { id: recolteId },
      data: {
        reconnaissanceIA: analysis,
        poidsEstimeKg: analysis.poidsEstime.kg
      }
    });
    
    // 4. Send notification
    await notifyUser(recolteId, analysis);
    
  } catch (error) {
    // Fallback manual entry
    await handleAIFailure(recolteId, error);
  }
});
```

## **üíæ Mod√®le de donn√©es (selon data_models_bas_malin.md)**

```prisma
model Recolte {
  id                String @id @default(cuid())
  utilisateurId     String
  instanceCultureId String?
  zoneId            String
  
  // Timing
  dateRecolte       DateTime
  heureRecolte      DateTime?
  
  // Quantit√©s
  poidsTotalKg      Decimal @db.Decimal(8,3)
  quantiteUnites    Int?
  valeurMarcheEstimee Decimal? @db.Decimal(8,2)
  
  // ‚≠ê IA Recognition (F2.5 - MUST HAVE PRIORIT√â 1)
  reconnaissanceIA  Json? // {varieteDetectee, scoreConfiance, poidsEstime, typeRecipient, tempsTraitementMs, versionModele, correctionManuelle}
  
  // Documentation visuelle
  photos            Json? // [{url, legende, analyseeIA, donneesReconnaissance}]
  
  // Qualit√©
  evaluationQualite Json? // {noteGenerale: 1-5, noteTaille: 1-5, noteGout: 1-5, noteApparence: 1-5}
  
  // G√©olocalisation pr√©cise (mobile)
  localisationRecolte Json? // {latitude, longitude, precisionMetres}
  
  // Relations
  utilisateur     User @relation(fields: [utilisateurId], references: [id])
  instanceCulture InstanceCulture? @relation(fields: [instanceCultureId], references: [id])
  zone            Zone @relation(fields: [zoneId], references: [id])
}
```

## **üì± Interface Mobile (Usage principal terrain)**

### **Scan & Recognition Flow**
```typescript
const MobileHarvestCapture = () => {
  const [image, setImage] = useState<string>();
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  const [analysis, setAnalysis] = useState<HarvestAnalysis>();

  const capturePhoto = async () => {
    // 1. Camera native avec g√©olocalisation
    const photo = await camera.takePhoto({
      quality: 0.8,
      includeMetadata: true,
      geoLocation: true
    });
    
    setImage(photo.uri);
    setIsAnalyzing(true);
    
    // 2. Upload imm√©diat + traitement IA
    const analysis = await harvestAPI.analyzePhoto(photo);
    setAnalysis(analysis);
    setIsAnalyzing(false);
  };

  const confirmHarvest = async () => {
    await harvestAPI.createRecolte({
      photo: image,
      recognition: analysis,
      location: getCurrentLocation(),
      timestamp: new Date()
    });
    
    // Notification succ√®s + retour liste
    showSuccessToast("R√©colte enregistr√©e !");
    navigation.navigate('HarvestList');
  };

  return (
    <div className="h-screen bg-green-50">
      {/* Camera preview ou image captur√©e */}
      <div className="h-2/3 relative">
        {image ? (
          <img src={image} className="w-full h-full object-cover" />
        ) : (
          <CameraPreview onCapture={capturePhoto} />
        )}
        
        {/* Overlay guide de cadrage */}
        <div className="absolute inset-0 flex items-center justify-center">
          <div className="w-80 h-80 border-2 border-white border-dashed rounded-lg">
            <p className="text-white text-center mt-4">
              Centrez votre r√©colte dans le cadre
            </p>
          </div>
        </div>
      </div>

      {/* R√©sultats reconnaissance IA */}
      <div className="h-1/3 p-4 bg-white">
        {isAnalyzing ? (
          <AIAnalyzingIndicator />
        ) : analysis ? (
          <HarvestResults analysis={analysis} onConfirm={confirmHarvest} />
        ) : (
          <CaptureInstructions />
        )}
      </div>
    </div>
  );
};

// Interface simplifi√©e occasionnel
const SimpleHarvestCapture = () => (
  <div className="p-6 space-y-6">
    <h1 className="text-2xl text-center">üì∏ Photographier ma r√©colte</h1>
    
    {/* Un seul gros bouton */}
    <Button 
      size="lg" 
      className="w-full h-20 text-xl"
      onClick={capturePhoto}
    >
      üì∑ Prendre une photo
    </Button>
    
    {/* IA fait le reste automatiquement */}
    {analysis && (
      <AutoConfirmResults 
        analysis={analysis} 
        autoSave={true}
        showDetails={false}
      />
    )}
  </div>
);
```

### **G√©olocalisation automatique**
```typescript
const useHarvestGeolocation = () => {
  const [location, setLocation] = useState<GeolocationData>();
  const [zone, setZone] = useState<Zone>();

  useEffect(() => {
    // G√©olocalisation pr√©cise avec GPS
    navigator.geolocation.getCurrentPosition(
      (position) => {
        const coords = {
          latitude: position.coords.latitude,
          longitude: position.coords.longitude,
          precision: position.coords.accuracy
        };
        
        setLocation(coords);
        
        // D√©termination automatique de la zone
        detectZoneFromCoordinates(coords).then(setZone);
      },
      { enableHighAccuracy: true, timeout: 10000 }
    );
  }, []);

  return { location, zone };
};
```

## **üíª Desktop (Registre & Analytics)**

### **Dashboard des r√©coltes**
```typescript
const DesktopHarvestDashboard = () => {
  const { data: recoltes } = useRecoltes();
  const { data: analytics } = useHarvestAnalytics();

  return (
    <div className="grid grid-cols-12 gap-6">
      {/* Liste des r√©coltes r√©centes */}
      <div className="col-span-8">
        <Card>
          <CardHeader>
            <CardTitle>R√©coltes r√©centes</CardTitle>
          </CardHeader>
          <CardContent>
            <HarvestTable 
              data={recoltes} 
              showAIAnalysis={true}
              showGeolocation={true}
            />
          </CardContent>
        </Card>
      </div>

      {/* M√©triques temps r√©el */}
      <div className="col-span-4 space-y-4">
        <MetricCard 
          title="R√©coltes cette semaine"
          value={analytics.weeklyHarvests}
          unit="kg"
          trend="+12%"
        />
        
        <MetricCard 
          title="Pr√©cision IA moyenne"
          value={analytics.aiAccuracy}
          unit="%"
          score="95.2%"
        />
        
        <MetricCard 
          title="Co√ªt IA ce mois"
          value={analytics.aiCostEuros}
          unit="‚Ç¨"
          budget="30‚Ç¨ max"
        />
      </div>
    </div>
  );
};

// Table avanc√©e avec colonnes IA
const HarvestTable = ({ data, showAIAnalysis }) => (
  <Table>
    <TableHeader>
      <TableRow>
        <TableHead>Photo</TableHead>
        <TableHead>Culture d√©tect√©e</TableHead>
        <TableHead>Poids (IA vs R√©el)</TableHead>
        <TableHead>Confiance IA</TableHead>
        <TableHead>Zone</TableHead>
        <TableHead>Actions</TableHead>
      </TableRow>
    </TableHeader>
    <TableBody>
      {data.map(recolte => (
        <TableRow key={recolte.id}>
          <TableCell>
            <img src={recolte.photos[0].url} className="w-12 h-12 rounded" />
          </TableCell>
          <TableCell>
            <div className="space-y-1">
              <Badge variant={recolte.reconnaissanceIA?.scoreConfiance > 0.9 ? "success" : "warning"}>
                {recolte.reconnaissanceIA?.varieteDetectee || "Non d√©tect√©"}
              </Badge>
              <p className="text-xs text-gray-500">
                Confiance: {(recolte.reconnaissanceIA?.scoreConfiance * 100).toFixed(1)}%
              </p>
            </div>
          </TableCell>
          <TableCell>
            <div className="space-y-1">
              <span className="font-medium">{recolte.poidsTotalKg}kg</span>
              {recolte.reconnaissanceIA?.poidsEstime && (
                <p className="text-xs text-gray-500">
                  IA: {recolte.reconnaissanceIA.poidsEstime}kg
                </p>
              )}
            </div>
          </TableCell>
          <TableCell>
            <ConfidenceScore score={recolte.reconnaissanceIA?.scoreConfiance} />
          </TableCell>
          <TableCell>{recolte.zone.nom}</TableCell>
          <TableCell>
            <DropdownMenu>
              <DropdownMenuTrigger asChild>
                <Button variant="ghost" size="sm">‚ãÆ</Button>
              </DropdownMenuTrigger>
              <DropdownMenuContent>
                <DropdownMenuItem>Corriger IA</DropdownMenuItem>
                <DropdownMenuItem>Voir d√©tails</DropdownMenuItem>
                <DropdownMenuItem>Supprimer</DropdownMenuItem>
              </DropdownMenuContent>
            </DropdownMenu>
          </TableCell>
        </TableRow>
      ))}
    </TableBody>
  </Table>
);
```

## **üì∫ TV (Spectaculaire visualization)**

### **Tableau de bord immersif**
```typescript
const TVHarvestShowcase = () => {
  const { data: recentHarvests } = useRecentHarvests(10);
  const { data: stats } = useHarvestStats();

  return (
    <div className="h-screen bg-gradient-to-br from-green-900 via-emerald-800 to-green-900 text-white">
      {/* Hero metrics */}
      <section className="h-1/3 flex items-center justify-center">
        <div className="text-center space-y-4">
          <h1 className="text-6xl font-bold">
            {stats.totalKgThisYear} kg
          </h1>
          <p className="text-2xl opacity-80">r√©colt√©s cette ann√©e</p>
          
          <div className="flex justify-center space-x-8 mt-8">
            <TVStat 
              icon="üìà" 
              value={`+${stats.growthPercent}%`}
              label="vs ann√©e pass√©e"
            />
            <TVStat 
              icon="ü§ñ" 
              value={`${stats.aiAccuracy}%`}
              label="pr√©cision IA"
            />
            <TVStat 
              icon="üìç" 
              value={stats.zoneCount}
              label="zones actives"
            />
          </div>
        </div>
      </section>

      {/* Galerie photos r√©centes avec animations */}
      <section className="h-2/3 p-8">
        <h2 className="text-3xl mb-6 text-center">Derni√®res r√©coltes</h2>
        
        <div className="grid grid-cols-5 gap-4 h-full">
          {recentHarvests.map((harvest, index) => (
            <TVHarvestCard 
              key={harvest.id}
              harvest={harvest}
              delay={index * 200} // Animation staggered
            />
          ))}
        </div>
      </section>
    </div>
  );
};

const TVHarvestCard = ({ harvest, delay }) => (
  <motion.div
    initial={{ opacity: 0, y: 50 }}
    animate={{ opacity: 1, y: 0 }}
    transition={{ delay: delay / 1000 }}
    className="relative group cursor-pointer"
  >
    <img 
      src={harvest.photos[0]?.url}
      className="w-full h-full object-cover rounded-lg"
    />
    
    {/* Overlay avec infos IA */}
    <div className="absolute inset-0 bg-black bg-opacity-0 group-hover:bg-opacity-60 transition-all duration-300 rounded-lg">
      <div className="absolute bottom-0 left-0 right-0 p-4 text-white transform translate-y-full group-hover:translate-y-0 transition-transform">
        <h3 className="text-lg font-bold">
          {harvest.reconnaissanceIA?.varieteDetectee || harvest.variete}
        </h3>
        <p>{harvest.poidsTotalKg}kg ‚Ä¢ {format(harvest.dateRecolte, 'dd/MM')}</p>
        
        {harvest.reconnaissanceIA?.scoreConfiance && (
          <div className="flex items-center space-x-2 mt-2">
            <span>ü§ñ</span>
            <div className="bg-white bg-opacity-20 rounded-full h-2 flex-1">
              <div 
                className="bg-green-400 rounded-full h-2"
                style={{ width: `${harvest.reconnaissanceIA.scoreConfiance * 100}%` }}
              />
            </div>
            <span className="text-xs">
              {(harvest.reconnaissanceIA.scoreConfiance * 100).toFixed(0)}%
            </span>
          </div>
        )}
      </div>
    </div>
  </motion.div>
);
```

## **üîÑ API Routes**

### **Endpoints principaux**
```typescript
// POST /api/harvests - Cr√©er r√©colte avec IA
export async function POST(request: NextRequest) {
  const session = await getServerSession(authOptions);
  if (!session) return unauthorized();

  const { photo, metadata } = await request.json();

  try {
    // 1. Upload photo s√©curis√©
    const photoUrl = await uploadPhoto(photo, session.user.id);
    
    // 2. Cr√©er r√©colte en attente
    const recolte = await prisma.recolte.create({
      data: {
        utilisateurId: session.user.id,
        dateRecolte: new Date(),
        photos: [{ url: photoUrl, priseA: new Date() }],
        localisationRecolte: metadata.geolocation,
        poidsTotalKg: 0 // En attente IA
      }
    });

    // 3. D√©clencher analyse IA asynchrone
    await harvestAIQueue.processHarvest(recolte.id, photoUrl);

    return NextResponse.json({ 
      recolte: recolte,
      status: 'analyzing',
      estimatedTime: '10-30 seconds'
    });

  } catch (error) {
    return handleAPIError(error);
  }
}

// GET /api/harvests/[id]/analysis - Status analyse IA
export async function GET(
  request: NextRequest,
  { params }: { params: { id: string } }
) {
  const recolte = await prisma.recolte.findUnique({
    where: { id: params.id },
    include: { 
      reconnaissanceIA: true,
      zone: true,
      instanceCulture: { include: { variete: true } }
    }
  });

  return NextResponse.json({
    status: recolte.reconnaissanceIA ? 'completed' : 'processing',
    analysis: recolte.reconnaissanceIA,
    confidence: recolte.reconnaissanceIA?.scoreConfiance,
    cost: recolte.reconnaissanceIA?.coutEstimeEuros
  });
}

// PATCH /api/harvests/[id]/correct - Correction manuelle IA
export async function PATCH(
  request: NextRequest,
  { params }: { params: { id: string } }
) {
  const { corrections } = await request.json();
  
  // Mise √† jour avec correction manuelle + feedback IA
  await prisma.recolte.update({
    where: { id: params.id },
    data: {
      reconnaissanceIA: {
        ...recolte.reconnaissanceIA,
        correctionManuelle: corrections,
        feedbackUtilisateur: corrections.feedback
      }
    }
  });

  // Am√©lioration continue du mod√®le
  await sendAIFeedback(corrections);
  
  return NextResponse.json({ success: true });
}
```

## **üîç Fallbacks & gestion d'erreurs**

### **Fallback local Ollama (EXG-005.3)**
```typescript
export class FallbackHarvestRecognition {
  private ollama = new Ollama({ baseURL: 'http://localhost:11434' });

  async analyzeWithLocalAI(imageBuffer: Buffer): Promise<HarvestAnalysis> {
    // Mod√®le Llama 3.1 Vision local en cas d'√©chec API externe
    const response = await this.ollama.generate({
      model: 'llava:13b', // Mod√®le vision local
      prompt: 'Analyze this harvest photo...',
      images: [imageBuffer.toString('base64')]
    });

    return {
      culture: { nom: 'D√©tection locale', scoreConfiance: 0.7 },
      poidsEstime: { kg: 0.5, scoreConfiance: 0.6, margeErreur: 25 },
      source: 'local_ai'
    };
  }

  async handleAPIFailure(recolteId: string, error: Error) {
    // Mode d√©grad√© : saisie manuelle guid√©e
    await prisma.recolte.update({
      where: { id: recolteId },
      data: {
        reconnaissanceIA: {
          status: 'failed',
          error: error.message,
          fallbackMode: 'manual_entry_required'
        }
      }
    });

    // Notification utilisateur mode d√©grad√©
    await sendNotification({
      userId: recolte.utilisateurId,
      type: 'ai_failure',
      message: 'Reconnaissance automatique indisponible. Saisie manuelle requise.'
    });
  }
}
```

## **‚úÖ Crit√®res d'acceptation**

### **Reconnaissance IA**
- [ ] **Pr√©cision culture : 95% minimum** (EXG-005.4)
- [ ] **Temps traitement : < 5 secondes** (EXG-005.4)
- [ ] Estimation poids ¬±10% pr√©cision
- [ ] D√©tection type r√©cipient (panier, cagette, bol...)
- [ ] Score confiance affich√© pour chaque pr√©diction

### **Interface utilisateur**
- [ ] **Mobile** : Scan photo en 1 clic, reconnaissance automatique
- [ ] **Interface Occasionnel** : Ultra-simplifi√©e, 3 clics maximum
- [ ] **Desktop** : Registre complet avec corrections manuelles
- [ ] **TV** : Galerie spectaculaire avec m√©triques temps r√©el

### **Performance & Co√ªts**
- [ ] **Budget IA : 20-30‚Ç¨/mois maximum** (EXG-005.1)
- [ ] Queue asynchrone BullMQ fonctionnelle
- [ ] Fallback local Ollama en cas d'indisponibilit√© API
- [ ] Monitoring co√ªts en temps r√©el

### **Donn√©es & Tra√ßabilit√©**
- [ ] G√©olocalisation automatique (zone de r√©colte)
- [ ] Tra√ßabilit√© compl√®te : semis ‚Üí culture ‚Üí r√©colte
- [ ] Export donn√©es CSV/JSON
- [ ] Analytics et comparaisons inter-annuelles

### **Qualit√© & Feedback**
- [ ] Feedback utilisateur pour am√©lioration IA
- [ ] Correction manuelle des pr√©dictions
- [ ] Logs complets des analyses (debugging)
- [ ] A/B testing diff√©rents mod√®les IA

## **üèóÔ∏è Exigences architecturales couvertes**

- **EXG-001.2** : API Routes `/src/app/api/harvests/*` ‚úÖ
- **EXG-002.1** : PostgreSQL pour stockage r√©coltes + analyses ‚úÖ
- **EXG-002.2** : Prisma ORM avec mod√®le Recolte ‚úÖ
- **EXG-003.1** : PWA offline pour saisie terrain ‚úÖ
- **EXG-005.1** : Utilisation optimale APIs existantes ‚úÖ
- **EXG-005.2** : BullMQ pour traitement asynchrone IA ‚úÖ
- **EXG-005.3** : Fallback Ollama local ‚úÖ
- **EXG-005.4** : GPT-4 Vision 95% pr√©cision < 5s ‚úÖ
- **EXG-007.3** : Performance < 2s hors traitement IA ‚úÖ

## **üí∞ Budget & ROI**

### **Co√ªts IA estim√©s**
- **GPT-4 Vision** : ~0.01‚Ç¨ per image
- **Usage pr√©vu** : 50 r√©coltes/semaine = 200/mois
- **Budget mensuel** : ~2-3‚Ç¨ (largement sous les 30‚Ç¨)
- **ROI** : Gain temps √©norme vs saisie manuelle

### **Optimisations co√ªt**
- Cache des analyses similaires (m√™me l√©gume + poids)
- Batch processing pour r√©duire les appels API
- Fallback local pour les cas simples
- A/B testing mod√®les moins chers pour validation

## **üöÄ Plan d'impl√©mentation**

### **Phase 1 : IA Core (4j)**
1. Configuration OpenAI GPT-4 Vision
2. Service de reconnaissance avec parsing JSON
3. Queue BullMQ + Worker asynchrone
4. Tests pr√©cision sur dataset photos

### **Phase 2 : Interface Mobile (3j)**  
1. Camera component avec cadrage guid√©
2. Upload photo + g√©olocalisation
3. Feedback temps r√©el analyse IA
4. Interface simplifi√©e occasionnel

### **Phase 3 : Desktop Analytics (2j)**
1. Dashboard r√©coltes avec m√©triques IA
2. Table avec corrections manuelles
3. Analytics co√ªts et pr√©cision
4. Export donn√©es

### **Phase 4 : TV Showcase (2j)**
1. Interface vitrine spectaculaire
2. Galerie photos avec animations
3. M√©triques temps r√©el
4. Mode pr√©sentation

### **Phase 5 : Fallbacks & Polish (3j)**
1. Integration Ollama local
2. Gestion erreurs robuste
3. Tests charge et optimisation
4. Documentation compl√®te

**Dur√©e totale estim√©e : 14 jours**